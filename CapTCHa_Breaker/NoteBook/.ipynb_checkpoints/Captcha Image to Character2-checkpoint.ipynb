{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.activations.relu import relu\n",
    "from mygrad.nnet.layers import max_pool\n",
    "#from mygrad.nnet.losses import huber_loss as softmax_crossentropy\n",
    "from mynn.losses.huber_loss import huber_loss as softmax_crossentropy\n",
    "from mynn.initializers.glorot_uniform import glorot_uniform\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.layers.conv import conv\n",
    "from noggin import create_plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import misc\n",
    "import mygrad as mg\n",
    "import pickle\n",
    "from mynn.layers.dropout import dropout \n",
    "import scipy\n",
    "%matplotlib notebook\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOG(): #Different size data: Dataset Samples\n",
    "    def __init__ (self):\n",
    "        init_kwargs = {'gain': np.sqrt(2)} #Might Change\n",
    "        self.conv1 = conv(3, 35 , 40, 2,stride=(2,2), \n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.conv2 = conv(35, 15, 1, 4, stride = ( 2 , 2),\n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.dense1 = dense(180, 90, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense2 = dense(90, 45, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense3 = dense(45, 15, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dropout = dropout(.5)\n",
    "    def __call__(self, image):\n",
    "        \"\"\"Input\n",
    "        ___________\n",
    "        image (Channel, Length, Width)\n",
    "        \n",
    "        Output\n",
    "        ___________\n",
    "        size 15 list\n",
    "        \n",
    "        \"\"\"\n",
    "        #return self.dense2(relu(self.dense1(relu)))\n",
    "        print(f\"The image before any layers is {image.shape}\")\n",
    "        x = relu(self.dropout(self.conv1(image)))\n",
    "        print(f\"The input after the first conv is {x.shape}\")\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        print(f\"The input after the first pool is {x.shape}\")\n",
    "        x = relu(self.dropout(self.conv2(x)))\n",
    "        print(f\"The input after the second conv is {x.shape}\")\n",
    "        x = max_pool(x, (2, 2), 2)\n",
    "        print(f\"The input after the second pool is {x.shape}\")\n",
    "\n",
    "        #x=mg.Tensor(np.ravel(x.data))\n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "        print(f\"The input after flattening is {x.shape}\")\n",
    "        \n",
    "        \n",
    "        x = relu (self.dense1(x))\n",
    "        print(f\"The input after the first dense layer is {x.shape}\")\n",
    "        x = relu (self.dropout(self.dense2(x)))\n",
    "        print(f\"The input after the second dense is {x.shape}\")\n",
    "        x = relu (self.dropout(self.dense3(x)))\n",
    "        print(f\"The input after the third dense is {x.shape}\")\n",
    "        x=np.rint(x.data)\n",
    "        #ret = []\n",
    "        #for i in np.arange(x.shape[0]):\n",
    "        #    ret.append(self.decoder(x[i]))\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        '''Returns the weights of the model'''\n",
    "        return list(self.conv1.parameters)+list(self.conv2.parameters)+list(self.dense1.parameters)+list(self.dense2.parameters)+list(self.dense3.parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__ (self):\n",
    "        init_kwargs = {'gain': np.sqrt(2)} #Might Change\n",
    "        self.conv1 = conv(3, 35 , 18, 2,stride=(2,2), \n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.conv2 = conv(35, 15, 14, 28, stride = ( 2 , 2),\n",
    "                          weight_initializer=glorot_uniform, \n",
    "                          weight_kwargs=init_kwargs)\n",
    "        self.dense1 = dense(210, 90, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense2 = dense(90, 45, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dense3 = dense(45, 15, \n",
    "                            weight_initializer=glorot_uniform, \n",
    "                            weight_kwargs=init_kwargs)\n",
    "        self.dropout = dropout(.5)\n",
    "    def __call__(self, image):\n",
    "        \"\"\"Input\n",
    "        ___________\n",
    "        image (Channel, Length, Width)\n",
    "        \n",
    "        Output\n",
    "        ___________\n",
    "        size 15 list\n",
    "        \n",
    "        \"\"\"\n",
    "        assert len(image.shape) ==3 or len(image.shape) ==4, f\"The size of input is {image.shape} while we need \"\n",
    "        #return self.dense2(relu(self.dense1(relu)))\n",
    "        #print(f\"The [model] image before any layers is {image.shape}\")\n",
    "        x = mg.Tensor(relu(self.dropout(self.conv1(image))).data,dtype=int)\n",
    "        #print(f\"The input after the first conv is {x.shape}\")\n",
    "        x = mg.Tensor(max_pool(x, (2, 2), 2).data,dtype=int)\n",
    "        #print(f\"The input after the first pool is {x.shape}\")\n",
    "        x = mg.Tensor(relu(self.dropout(self.conv2(x))).data,dtype=int)\n",
    "        #print(f\"The input after the second conv is {x.shape}\")\n",
    "        x = mg.Tensor(max_pool(x, (2, 2), 2).data,dtype=int)\n",
    "        #print(f\"The input after the second pool is {x.shape}\")\n",
    "\n",
    "        #x=mg.Tensor(np.ravel(x.data))\n",
    "        x = mg.Tensor(x.reshape(x.shape[0], -1).data,dtype=int) \n",
    "        #print(f\"The input after flattening is {x.shape}\")\n",
    "        \n",
    "        \n",
    "        x = mg.Tensor(relu (self.dense1(x)).data,dtype=int)\n",
    "        #print(f\"The input after the first dense layer is {x.shape}\")\n",
    "        x = mg.Tensor(relu (self.dropout(self.dense2(x))).data,dtype=int)\n",
    "        #print(f\"The input after the second dense is {x.shape}\")\n",
    "        x = mg.Tensor(relu (self.dropout(self.dense3(x))).data,dtype=int)\n",
    "        #print(f\"The input after the third dense is {x.shape}\")\n",
    "        x=np.rint(x.data)\n",
    "        #ret = []\n",
    "        #for i in np.arange(x.shape[0]):\n",
    "        #    ret.append(self.decoder(x[i]))\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        '''Returns the weights of the model'''\n",
    "        return list(self.conv1.parameters)+list(self.conv2.parameters)+list(self.dense1.parameters)+list(self.dense2.parameters)+list(self.dense3.parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderdecrepit(x):\n",
    "        \"\"\"Input the numpy array from the call function\n",
    "        Input\n",
    "        __________________\n",
    "        list 15 or less alphanumeric \n",
    "        \n",
    "        Output\n",
    "        __________________\n",
    "        List of size 15 or less\"\"\"\n",
    "        assert isinstance(x, list), f\"This is not a valid input it is not the right type but the type given was {type(x)}\"\n",
    "        assert len(x) <= 15, f\"The call function should be getting a length 15 or less but you are not getting that, you are getting {len(x)}\"\n",
    "        \n",
    "        alphabet =\"abcdefghijklmnop\"\n",
    "        ret=np.zeros((15))\n",
    "        index=0\n",
    "        for i in x:\n",
    "            if isinstance(i, str):\n",
    "                i = ord(i)-87 \n",
    "                ret[index]=i\n",
    "                \n",
    "            \n",
    "            if  isinstance(i,int) and i>=0 and i<10:\n",
    "                ret[index]=i\n",
    "                \n",
    "            if i> 36 or i<0:\n",
    "                print(\"There is a problem\")\n",
    "                ret[index]=i\n",
    "            index+=1\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    __________\n",
    "    List of len 15 or less (alphanumeric)\n",
    "    \n",
    "    \n",
    "    Output\n",
    "    __________\n",
    "    np.ndarray 15\n",
    "    \n",
    "    Side note, I could have made this with the encodings python has already \"\"\"\n",
    "    assert isinstance(x, list), f\"You need to input a list, you inputted a {type(x)}\"\n",
    "    assert len(x)<=15, f\"You needed a 15 or less length list\"\n",
    "    \n",
    "    while (len(x)<15):\n",
    "        x.append(\" \")\n",
    "    codex = {\"0\":0, \"1\":1,\"2\":2,\"3\":3,\"4\":4,\"5\":5,\"6\":6,\"7\":7,\"8\":8,\"9\":9, \"a\":10, \"b\":11,\n",
    "             \"c\":12,\"d\":13,\"e\":14,\"f\":15,\"g\":16,\"h\":17,\"i\":18,\"j\":19,\"k\":20,\"l\":21,\n",
    "             \"m\":22,\"n\":23,\"o\":24,\"p\":25,\"q\":26,\"r\":27,\"s\":28,\"t\":29,\"u\":30,\"v\":31,\n",
    "             \"w\":32,\"x\":33,\"y\":34,\"z\":35,\" \":36}\n",
    "    ret = np.zeros(15)\n",
    "    for i in np.arange(15):\n",
    "        ret[i]= codex[str(x[i])]\n",
    "        \n",
    "    \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(x):\n",
    "        \"\"\"Input the numpy array from the call function\n",
    "        Input\n",
    "        __________________\n",
    "        np.ndarray shape (15,) with only integers \n",
    "        \n",
    "        Output\n",
    "        __________________\n",
    "        List of size 15 or less\"\"\"\n",
    "        assert isinstance(x, np.ndarray), f\"This is not a valid input it is not the right type but the type given was {type(x)}\"\n",
    "        \n",
    "        \n",
    "        assert x.shape[-1] == 15, f\"The call function should be giving you length 15 but you are not getting that, you are getting {x.shape}\"\n",
    "        \n",
    "        alphabet =\"abcdefghijklmnopqrstuvwxyz\"\n",
    "        ret=[]\n",
    "        \n",
    "        \n",
    "        for i in np.arange(x.shape[-1]):\n",
    "            if x[i]>=0 and x[i]<10:\n",
    "                ret.append(str(i))\n",
    "                continue\n",
    "            if x[i]>9 and x[i]<36:\n",
    "                c=i-10\n",
    "                ret.append(alphabet[c])\n",
    "                continue\n",
    "            if x[i]==36:\n",
    "                ret.append(\" \")\n",
    "            if x[i]> 36 or x[i]<0:\n",
    "                print(\"There is a problem\")\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mynn.optimizers.sgd import SGD\n",
    "\n",
    "model = Model()\n",
    "optim = SGD(model.parameters, learning_rate=0.01, momentum=0.9, weight_decay=5e-04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\noggin\\plotter.py:359: UserWarning: Live plotting is not supported when matplotlib uses the 'module://ipykernel.pylab.backend_inline'\n",
      "backend. Instead, use the 'nbAgg' backend.\n",
      "\n",
      "In a Jupyter notebook, this can be activated using the cell magic:\n",
      "   %matplotlib notebook.\n",
      "  warn(cleandoc(_inline_msg.format(self._backend)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter, fig, ax = create_plot([\"loss\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, truth):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    Prediction a np.ndarray\n",
    "    Truth a np.ndarray\n",
    "    _________________________\n",
    "    \n",
    "    Output\n",
    "    ret an integer\n",
    "    _________________________\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(prediction,mg.Tensor):\n",
    "        prediction= prediction.data\n",
    "    if isinstance(truth,mg.Tensor):\n",
    "        truth= truth.data\n",
    "    ret=0\n",
    "    \n",
    "    #if len(prediction.shape)<2:\n",
    "    #    prediction.reshape((1,prediction.shape))\n",
    "    #for i in np.arange(prediction.shape[0]):\n",
    "    #    ret+=i\n",
    "    #scipy.spatial.distance.cosine(prediction, truth)[source]\n",
    "    ret= np.dot(np.linalg.norm(prediction),np.linalg.norm(truth))\n",
    "    return 1-np.abs(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x is (1070, 3, 50, 200)\n",
      "(1184, 3, 96, 216)\n",
      "x and y are compatable\n"
     ]
    }
   ],
   "source": [
    "x_total=np.zeros((1070,3,50,200))\n",
    "x_2total=[]\n",
    "y_2total=[]\n",
    "y_total=np.zeros((1070,15))\n",
    "w_total=[]\n",
    "xy_total = {}\n",
    "index=0\n",
    "for entry in os.listdir(\"DataSets\\samples\"):\n",
    "    if os.path.isfile(os.path.join(\"DataSets\\samples\", entry)):\n",
    "        \n",
    "        V= \"DataSets\\samples\" \n",
    "        #print(f\"The file length for {entry} is {(misc.imread(os.path.join(V, entry))).shape}\")\n",
    "        if misc.imread(os.path.join(\"DataSets\\samples\", entry),mode = 'RGB').shape[-1] ==3:  \n",
    "            word = entry[:-4]\n",
    "            zed=misc.imread(os.path.join(\"DataSets\\samples\", entry),mode = 'RGB').transpose(2,0,1)\n",
    "            x_total[index]=zed\n",
    "            \n",
    "            w_total.append(word)\n",
    "            y_total[index]= encoder(list(word))\n",
    "            xy_total[word]= (x_total[index],y_total[index])\n",
    "            index+=1\n",
    "        else:\n",
    "            print(f\"{entry} is invalid\")\n",
    "\n",
    "for entry in os.listdir(\"DataSets\\MicrosoftDataSet\"):\n",
    "    if os.path.isfile(os.path.join(\"DataSets\\MicrosoftDataSet\", entry)):\n",
    "        \n",
    "        V= \"DataSets\\MicrosoftDataSet\" \n",
    "        #print(f\"The file length for {entry} is {(misc.imread(os.path.join(V, entry))).shape}\")\n",
    "        if misc.imread(os.path.join(\"DataSets\\MicrosoftDataSet\", entry),mode = 'RGB').shape[-1] ==3:  \n",
    "            word = ((entry[:-4]).lower()).split()[0]\n",
    "            zed=misc.imread(os.path.join(\"DataSets\\MicrosoftDataSet\", entry),mode = 'RGB').transpose(2,0,1)\n",
    "            x_2total.append(zed)\n",
    "            \n",
    "            w_total.append(word)\n",
    "            \n",
    "            y_2total.append(encoder(list(word)))\n",
    "            xy_total[word]= (zed,encoder(list(word)))\n",
    "            \n",
    "        else:\n",
    "            print(f\"{entry} is invalid\") \n",
    "x_2total=np.array(x_2total)\n",
    "y_2total=np.array(y_2total)\n",
    "print(f\" x is {x_total.shape}\")\n",
    "print(x_2total.shape)\n",
    "x_total = x_2total\n",
    "y_total = y_2total\n",
    "if x_total.shape[0]==y_total.shape[0]:\n",
    "    print(\"x and y are compatable\")\n",
    "else:\n",
    "    print(\"x and y are not compatable\")\n",
    "#print(f'x_length is {x_total.shape} and y_length is {y_total.shape}, xy_length is {len(xy_total.values)}, words is {len(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = x_total.astype(int)\n",
    "y_total = y_total.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  3 25 32 22  6 31 22 36 36 36 36 36 36 36]\n"
     ]
    }
   ],
   "source": [
    "print(y_total[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x is 900 , y is 900\n"
     ]
    }
   ],
   "source": [
    "x_train = x_total[:900]\n",
    "y_train = y_total[:900]\n",
    "x_test = x_total[900:]\n",
    "y_test = y_total[900:]\n",
    "print(f\" x is {x_train.shape[0]} , y is {y_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d= mg.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "batch_size = 100\n",
    "h=0\n",
    "g = []\n",
    "\n",
    "# We will train for ~10 epochs; you can change this if you'd like\n",
    "for epoch_cnt in range(10):\n",
    "    idxs = np.arange(len(x_train))  # -> array([0, 1, ..., 9999])\n",
    "    np.random.shuffle(idxs)  \n",
    "    \n",
    "    for batch_cnt in range(len(x_train)//batch_size):\n",
    "        batch_indices = idxs[batch_cnt*batch_size : (batch_cnt + 1)*batch_size]\n",
    "        batch = x_train[batch_indices]  # random batch of our training data\n",
    "\n",
    "        # compute the predictions for this batch by calling on model\n",
    "        prediction = model(batch)\n",
    "\n",
    "        # compute the true (a.k.a desired) values for this batch: \n",
    "        truth = y_train[batch_indices]\n",
    "\n",
    "        # compute the loss associated with our predictions(use softmax_cross_entropy)\n",
    "        #print(f\"predictions is {prediction.shape} and truth is {truth.shape}\")\n",
    "        loss = softmax_crossentropy(prediction, truth)\n",
    "\n",
    "        # back-propagate through your computational graph through your loss\n",
    "        loss.backward()\n",
    "\n",
    "        # compute the accuracy between the prediction and the truth \n",
    "        acc = accuracy(prediction, truth)\n",
    "        #print(f\"acc is {acc} of type {type(acc)} the shape is {acc.shape}\")\n",
    "\n",
    "        # execute gradient descent by calling step() of optim\n",
    "        optim.step()\n",
    "        \n",
    "        # null your gradients (please!)\n",
    "        loss.null_gradients()\n",
    "        \n",
    "        # set the training loss and accuracy\n",
    "\n",
    "        plotter.set_train_batch({\"loss\" : loss.item(),\n",
    "                                 \"accuracy\" : acc},\n",
    "                                 batch_size=batch_size)\n",
    "    \n",
    "    # Here, we evaluate our model on batches of *testing* data\n",
    "    # this will show us how good our model does on data that \n",
    "    # it has never encountered\n",
    "    # Iterate over batches of *testing* data\n",
    "    for batch_cnt in range(0, len(x_test)//batch_size):\n",
    "        idxs = np.arange(len(x_test))\n",
    "        batch_indices = idxs[batch_cnt*batch_size : (batch_cnt + 1)*batch_size]\n",
    "        batch = x_test[batch_indices] \n",
    "        \n",
    "        # get your model's prediction on the test-batch\n",
    "        try:\n",
    "            prediction = model(batch) #Was batch.transpose((1,2, 0))\n",
    "        except Exception as e:\n",
    "            print(batch.shape)\n",
    "            print(f\"Exception: {e} \\n model size is {batch.size}\")\n",
    "            pickle.dump(Model, open(\"Error batch #\"+str(h), 'wb'))\n",
    "            h+=1\n",
    "            g.append(batch)\n",
    "        # get the truth values for that test-batch\n",
    "        truth = y_test[batch_indices]\n",
    "        # compute the test accuracy\n",
    "        acc = accuracy(prediction, truth)\n",
    "        \n",
    "        \n",
    "        # DO NOT back-prop or do gradient descent!\n",
    "        \n",
    "        # log the test-accuracy in noggin\n",
    "        plotter.set_test_batch({\"accuracy\": acc}, batch_size=batch_size)\n",
    "    \n",
    "    plotter.set_train_epoch()\n",
    "    plotter.set_test_epoch()\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Model.parameters)\n",
    "try:\n",
    "    pickle.dump(Model, open(\"Weights.txt\", 'wb'))\n",
    "except:\n",
    "    print(\"Fail1\")\n",
    "try:\n",
    "    pickle.dump(Model,open(\"Weights.npy\",\"wb\"))\n",
    "except:\n",
    "    print(\"Fail2\")\n",
    "try:\n",
    "    pickle.dump(Model.parameters, open(\"Weights1.txt\", 'wb'))\n",
    "except:\n",
    "    print(\"Fail2\")\n",
    "try:\n",
    "    pickle.dump(Model.parameters,open(\"Weights1.npy\",\"wb\"))\n",
    "except:\n",
    "    print(\"Fail3\")\n",
    "    #np.save(\"Weights.txt\", Model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"Weights.txt\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_total.shape)\n",
    "#print(y_total[100])\n",
    "x=x_total[100:101]\n",
    "print(f\"value is {y_total[100:101]}\")\n",
    "x.reshape((1,3,50,200))\n",
    "print(x.shape)\n",
    "z = model(x)\n",
    "print(decoder(z[0]))\n",
    "print(f\"y decoded is {decoder(y_total[100])}\")\n",
    "print(f\"word is {w_total[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = list(xy_total.keys())[0]\n",
    "x,y =xy_total[Z]\n",
    "d = np.zeros((1,3,50,200))\n",
    "d[0]= x\n",
    "x= d\n",
    "mx = model(x)\n",
    "print(f\"Example is {Z}\")\n",
    "print(f\"y is {y} of type {type(y)}, size {y.shape}\")\n",
    "print(f\"Model returns:{mx}\")\n",
    "print(f\"Model decoded is {decoder(mx[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
